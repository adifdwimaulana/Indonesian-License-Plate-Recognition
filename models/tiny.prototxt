name: "1.0 MobileNet-128"
layer {
  name: "data"
  type: "OnDiskData"
  top: "data"
  input_param { shape: { dim: 1 dim: 1 dim: 32 dim: 32 } }
  data_param { source: "/home/busta/data/SynthText/train_icdar.txt" }
  top: "gt_boxes"
  top: "gt_labels"
  top: "line_boxes"
  top: "line_labels"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 32
    kernel_size: 3
    pad: 1
    stride: 2
    bias_term: false
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "scale1"
}

layer {
  name: "relu1"
  type: "ReLU"
  bottom: "scale1"
  top: "scale1"
  relu_param{
    negative_slope: 0.1
  }   
}

layer{
  name: "conv2"
  type: "Convolution"
  bottom: "scale1"
  top: "conv2"
  convolution_param {
    num_output: 32
    kernel_size: 3
    pad: 1
    stride: 2
    bias_term: false
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "scale2"
}

layer {
  name: "relu2"
  type: "ReLU"
  bottom: "scale2"
  top: "scale2"
  relu_param{
    negative_slope: 0.1
  }   
}

layer{
  name: "conv3"
  type: "Convolution"
  bottom: "scale2"
  top: "conv3"
  convolution_param {
    num_output: 64
    kernel_size: 3
    pad: 1
    stride: 1
    bias_term: false
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "scale3"
}

layer {
  name: "relu3"
  type: "ReLU"
  bottom: "scale3"
  top: "scale3"
  relu_param{
    negative_slope: 0.1
  }   
}

layer{
  name: "conv5"
  type: "Convolution"
  bottom: "scale3"
  top: "conv5"
  convolution_param {
    num_output: 64
    kernel_size: 3
    pad: 1
    stride: 2
    bias_term: false
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "conv5"
  top: "scale5"
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "scale5"
  top: "scale5"
  relu_param{
    negative_slope: 0.1
  }   
}

layer{
  name: "conv6"
  type: "Convolution"
  bottom: "scale5"
  top: "conv6"
  convolution_param {
    num_output: 128
    kernel_size: 3
    pad: 1
    stride: 1
    bias_term: false
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn6"
  type: "BatchNorm"
  bottom: "conv6"
  top: "scale6"
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "scale6"
  top: "scale6"
  relu_param{
    negative_slope: 0.1
  }   
}

layer{
  name: "conv8"
  type: "Convolution"
  bottom: "scale6"
  top: "conv8"
  convolution_param {
    num_output: 128
    kernel_size: 3
    pad: 1
    stride: 1
    bias_term: false
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn8"
  type: "BatchNorm"
  bottom: "conv8"
  top: "scale8"
}
layer {
  name: "relu8"
  type: "ReLU"
  bottom: "scale8"
  top: "scale8"
  relu_param{
    negative_slope: 0.1
  }   
}
layer {
  name: "pool8"
  type: "Pooling"
  bottom: "scale8"
  top: "pool8"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

layer{
  name: "conv9"
  type: "Convolution"
  bottom: "pool8"
  top: "conv9"
  convolution_param {
    num_output: 256
    kernel_size: 3
    pad: 1
    stride: 1
    bias_term: false
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn9"
  type: "BatchNorm"
  bottom: "conv9"
  top: "scale9"
}
layer {
  name: "relu9"
  type: "ReLU"
  bottom: "scale9"
  top: "scale9"
  relu_param{
    negative_slope: 0.1
  }   
}

layer{
  name: "conv11"
  type: "Convolution"
  bottom: "scale9"
  top: "conv11"
  convolution_param {
    num_output: 256
    kernel_size: 3
    pad: 1
    stride: 1
    bias_term: false
    weight_filler {
      type: "xavier"
    }
  }
  param {  
    name: "conv11_w"
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "scale11"
  relu_param{
    negative_slope: 0.1
  }   
}

layer{
  name: "conv11_2"
  type: "Convolution"
  bottom: "scale11"
  top: "conv11_2"
  convolution_param {
    num_output: 256
    kernel_size: 3
    pad: 1
    stride: 1
    bias_term: false
    weight_filler {
      type: "xavier"
    }
  }
  param {
    name: "conv11_w"
  }
}
layer {
  name: "bn11_2"
  type: "BatchNorm"
  bottom: "conv11_2"
  top: "scale11_2"
}
layer {
  name: "relu11_2"
  type: "ReLU"
  bottom: "scale11_2"
  top: "scale11_2"
  relu_param{
    negative_slope: 0.1
  }   
}

#####
layer {
  name: "conv14/3x3"
  type: "Convolution"
  bottom: "scale11_2"
  top: "conv14/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    group: 256
    weight_filler {
      type: "msra"
    }
    bias_term: false
    engine: CAFFE
  }
}
layer {
  name: "conv14/3x3/bn"
  type: "BatchNorm"
  bottom: "conv14/3x3"
  top: "conv14/3x3/bn"
}
layer {
  name: "conv14/3x3/scale"
  type: "Scale"
  bottom: "conv14/3x3/bn"
  top: "conv14/3x3/bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv14/relu1"
  type: "ReLU"
  bottom: "conv14/3x3/bn"
  top: "conv14/3x3/bn"
  relu_param{
    negative_slope: 0.1
  }  
}
layer {
  name: "conv14/1x1"
  type: "Convolution"
  bottom: "conv14/3x3/bn"
  top: "conv14/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  bias_term: false
  }
}
layer {
  name: "conv14/1x1/bn"
  type: "BatchNorm"
  bottom: "conv14/1x1"
  top: "conv14/1x1/bn"
}
layer {
  name: "conv14/1x1/scale"
  type: "Scale"
  bottom: "conv14/1x1/bn"
  top: "conv14/1x1/bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv14/relu2"
  type: "ReLU"
  bottom: "conv14/1x1/bn"
  top: "conv14/1x1/bn"
  relu_param{
    negative_slope: 0.1
  }  
}
#####
layer {
  name: "conv15/3X3"
  type: "Convolution"
  bottom: "conv14/1x1/bn"
  top: "conv15/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    group: 512
    #dilation: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
    engine: CAFFE
  }
}
layer {
  name: "conv15/3x3/bn"
  type: "BatchNorm"
  bottom: "conv15/3x3"
  top: "conv15/3x3/bn"
}
layer {
  name: "conv15/3x3/scale"
  type: "Scale"
  bottom: "conv15/3x3/bn"
  top: "conv15/3x3/bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv15/relu1"
  type: "ReLU"
  bottom: "conv15/3x3/bn"
  top: "conv15/3x3/bn"
  relu_param{
    negative_slope: 0.1
  }  
}
layer {
  name: "conv15/1x1"
  type: "Convolution"
  bottom: "conv15/3x3/bn"
  top: "conv15/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  bias_term: false
  }
}
layer {
  name: "conv15/1x1/bn"
  type: "BatchNorm"
  bottom: "conv15/1x1"
  top: "conv15/1x1/bn"
}
layer {
  name: "conv15/1x1/scale"
  type: "Scale"
  bottom: "conv15/1x1/bn"
  top: "conv15/1x1/bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv15/relu2"
  type: "ReLU"
  bottom: "conv15/1x1/bn"
  top: "conv15/1x1/bn"
  relu_param{
    negative_slope: 0.1
  }  
}
#####


layer {
  name: "concat1"
  type: "Concat"
  bottom: "scale8"
  top: "concat1"
}

layer {
  name: "reorg1"
  type: "Reorg"
  bottom: "concat1"
  top: "reorg1"
  reorg_param{
    stride: 2
  }
}

layer {
  name: "concat2"
  type: "Concat"
  bottom: "reorg1"
  bottom: "conv15/1x1/bn"
  top: "concat2"
}
##################
layer {
  name: "conv16/1x1"
  type: "Convolution"
  bottom: "concat2"
  top: "conv16/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  bias_term: false
  }
}
layer {
  name: "conv16/1x1/bn"
  type: "BatchNorm"
  bottom: "conv16/1x1"
  top: "conv16/1x1/bn"
}
layer {
  name: "conv16/1x1/scale"
  type: "Scale"
  bottom: "conv16/1x1/bn"
  top: "conv16/1x1/bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv16/relu2"
  type: "ReLU"
  bottom: "conv16/1x1/bn"
  top: "conv16/1x1/bn"
  relu_param{
    negative_slope: 0.1
  }  
}
########################

layer{
  name: "conv_20/3x3"
  type: "Convolution"
  bottom: "conv16/1x1/bn"
  top: "conv20/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    group: 512
    weight_filler {
      type: "msra"
    }
    bias_term: false
    engine: CAFFE
  }
}

layer {
  name: "conv20/3x3/bn"
  type: "BatchNorm"
  bottom: "conv20/3x3"
  top: "conv20/3x3/bn"
}
layer {
  name: "conv20/3x3/scale"
  type: "Scale"
  bottom: "conv20/3x3/bn"
  top: "conv20/3x3/bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv20/relu1"
  type: "ReLU"
  bottom: "conv20/3x3/bn"
  top: "conv20/3x3/bn"
  relu_param{
    negative_slope: 0.1
  }  
}
layer {
  name: "conv20/1x1"
  type: "Convolution"
  bottom: "conv20/3x3/bn"
  top: "conv20/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  bias_term: false
  }
}
layer {
  name: "conv20/1x1/bn"
  type: "BatchNorm"
  bottom: "conv20/1x1"
  top: "conv20/1x1/bn"
}
layer {
  name: "conv20/1x1/scale"
  type: "Scale"
  bottom: "conv20/1x1/bn"
  top: "conv20/1x1/bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv20/relu2"
  type: "ReLU"
  bottom: "conv20/1x1/bn"
  top: "conv20/1x1/bn"
  relu_param{
    negative_slope: 0.1
  }  
}

##########################

layer{
  name: "conv_22"
  type: "Convolution"
  bottom: "conv20/1x1/bn"
  top: "conv22"
  convolution_param {
    num_output: 168
    kernel_size: 1
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}

layer {
  name: "transpose"
  type: "Transpose"
  bottom: "conv22"
  top: "transpose"
  transpose_param {
    dim: 0 
    dim: 2
    dim: 3
    dim: 1
  }
}

layer{
  name: "RegionLayer"
  type: "Region"
  bottom: "transpose"
  bottom: "gt_boxes"
  top: "loss"
  loss_weight: 1
  top: "boxes"
  loss_weight: 0
  top: "trans"
  loss_weight: 0
  region_param:{
    classes: 6
    coords: 5
    boxes_of_each_grid: 14
    softmax: true
    nms_threshold: 0.5
    expand_bias: false 
  }
}

layer {
  name: "dummy"
  type: "ReLU"
  bottom: "loss"
  top: "out"
  loss_weight: 1
  relu_param{
    negative_slope: 0.1
  }   
}
